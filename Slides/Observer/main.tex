\documentclass{beamer}

\input{settings.tex}


\title{Observers}
\subtitle{Control Theory, Lecture 8}
\author{by Sergei Savin}
\centering
\date{\mydate}



\begin{document}
\maketitle



\begin{frame}{Content}
\begin{itemize}
\item Measurement
\item State Estimation
\item Observer
\item Observation and Control
\item Separation principle
\end{itemize}
\end{frame}




\begin{frame}{Measurement and control}
%\framesubtitle{How do we know the state?}
\begin{flushleft}

Before we considered systems and control laws of the following type:

\begin{equation}
\begin{cases}
\dot {\bo{x}} = \bo{A} \bo{x} + \bo{B} \bo{u}\\
\bo{u} = \bo{K} \bo{x}
\end{cases}
\end{equation}

But when we implement that control law, how do we know the current value of $\bo{x}$?

\bigskip

In practice, we can \emph{estimate} it using \emph{measurement}.

\end{flushleft}
\end{frame}

\begin{frame}{Why information is imperfect?}
%\framesubtitle{Why information is imperfect?}
\begin{flushleft}

There are a number of reasons why we can not directly measure the state of the system. Here are some:

\begin{itemize}
\item Digital measurements are done in discrete time intervals.
\item Unpredicted events (faults, collisions, etc.).
\item Un-modelled kinematics or dynamics (links bending, gear box backlash,  friction, etc.) making the very definition of the state disconnected from reality.
\item Lack of sensors.
\item Imprecise, nonlinear and biased sensors.
\item Other physical effects.
\end{itemize}

\end{flushleft}
\end{frame}

\begin{frame}{Measurement and estimation}
%\framesubtitle{Definition}
\begin{flushleft}

Let us introduce new notation. We have an LTI system of the following form:

\begin{equation}
\begin{cases}
\dot {\bo{x}} = \bo{A} \bo{x} + \bo{B} \bo{u} \\
\bo{y} = \bo{C} \bo{x} \\
\hat{\bo{x}}(t) = \text{estimate} \ (\bo{y}(t)) \\
\bo{u} = -\bo{K}\hat{\bo{x}}
\end{cases}
\end{equation}

Then:

\begin{itemize}
\item $\bo{x}$ and $\bo{y}$ are the state and output (actual or true)
\item $\hat{\bo{x}}$ and $\hat{\bo{y}} =\bo{C} \hat{\bo{x}}$ are the estimated (observed) state
and output.
\end{itemize}

Notice that we never know true state $\bo{x}$, and therefore for the control purposes we have to use the estimated state $\hat{\bo{x}}$.

\end{flushleft}
\end{frame}




\begin{frame}{Estimation error}
	%\framesubtitle{Observer}
	\begin{flushleft}
		
		How can we quantify the error in our estimation? We can do it directly as state estimation error:
		
		\begin{equation}
			\varepsilon = \hat{\bo{x}} - \bo{x}
		\end{equation}
		
		But this is impossible to compute, since we do not know $\bo{x}$. Alternatively, we can compare measured output $\bo{y}$ with estimated output $\hat{\bo{y}} =\bo{C} \hat{\bo{x}}$:
		
		\begin{equation}
			\Tilde{\bo{y}} = \bo{C} \hat{\bo{x}} - \bo{y} 
		\end{equation}		
		
		This can always be computed.
		
	\end{flushleft}
\end{frame}



\begin{frame}{Estimation - dynamics}
%\framesubtitle{Using the knowledge about dynamics}
\begin{flushleft}

Let us consider autonomous dynamical system
\begin{equation}
\label{eq:LTI}
\begin{cases}
\dot {\bo{x}} = \bo{A} \bo{x} + \bo{B} \bo{u} \\
\bo{y} = \bo{C} \bo{x}
\end{cases}
\end{equation}
%
with measurements $\bo{y}$. We want to get as good an estimate of the state $\hat{\bo{x}}$ as we can.

\bigskip

First note: dynamics should also hold for our observed state:
\begin{equation}
\hat{\dot {\bo{x}}} = \bo{A} \hat{\bo{x}} + \bo{B} \bo{u}
\end{equation}
%
Therefore if we know the initial conditions of our system exactly, and we know our model exactly, we can find exact state of the system without using measurement $\bo{y}$. We can call it an open loop observation. Unfortunately, we know neither the model nor the initial conditions precisely.


\end{flushleft}
\end{frame}





\begin{frame}{Estimation - observer}
%\framesubtitle{Observer}
\begin{flushleft}

We propose \emph{observer} that takes into account measurements in a linear way; analogues with linear control $-\bo{K}\bo{x}$, here we propose a linear law $-\bo{L}\Tilde{\bo{y}}$. Remembering that $\Tilde{\bo{y}} = \bo{C} \hat{\bo{x}} - \bo{y}$ we get:

\begin{equation}
\label{eq:Observer}
\hat{\dot {\bo{x}}} = \bo{A} \hat{\bo{x}} + \bo{B} \bo{u} + \bo{L}(\bo{y} - \bo{C} \hat{\bo{x}})
\end{equation}
%
With this observer, we want to get as good estimate of the state $\hat{\bo{x}}$ as we can.

\bigskip

We can subtract \eqref{eq:LTI} from \eqref{eq:Observer}, to get \emph{observer error dynamics}:

\begin{equation}
\hat{\dot {\bo{x}}} - \dot {\bo{x}}= 
\bo{A} \hat{\bo{x}} - \bo{A} \bo{x} + 
\bo{L}(\mathbf y - \bo{C} \hat{\bo{x}})
\end{equation}
%
\begin{equation}
\dot {\varepsilon}= 
(\bo{A} - \bo{L} \bo{C}) \varepsilon
\end{equation}

\end{flushleft}
\end{frame}



\begin{frame}{Observer gains}
%\framesubtitle{Observer gains}
\begin{flushleft}

The observer $\dot {\varepsilon}= 
(\bo{A} - \bo{L} \bo{C}) \varepsilon$ is \emph{stable} (i.e., the state estimation error tends to zero), as long as the following matrix has eigenvalues with negative real parts:

\[
\bo{A} - 
\bo{L} \bo{C} \in \mathbb{H}
\]

We need to find $\bo{L}$. Let us observe the key difference between observer design and controller design:

\bigskip

\begin{itemize}
    \item Controller design: find such $\bo{K}$ that $\bo{A} - \bo{B} \bo{K} \in \mathbb{H}$.
    \item Observer design: find such $\bo{L}$ that: $\bo{A} - \bo{L} \bo{C} \in \mathbb{H}$
\end{itemize}

\bigskip

We have instruments for finding $\bo{K}$, what about $\bo{L}$?

\end{flushleft}
\end{frame}


\begin{frame}{Observer Design}
\framesubtitle{General case: design via Riccati eq.}
\begin{flushleft}

In general, we can observe that if $\bo{A} - \bo{L} \bo{C}\in \mathbb{H}$, then $(\bo{A} - 
\bo{L} \bo{C})^{\top}\in \mathbb{H}$ (eigenvalues of a matrix and its transpose are the same, see Appendix). 

\bigskip

Therefore, we can solve the following \emph{dual problem}:

\begin{itemize}
    \item find such $\bo{L}$ that $\bo{A}^{\top} - 
\bo{C}^{\top} \bo{L}^{\top} \in \mathbb{H}$.
\end{itemize}

\bigskip

The dual problem is \emph{equivalent} to the control design problem. We can solve it by producing and solving algebraic Riccati equation, as in the LQR formulation. In pseudo-code it can be represented the following way:

\bigskip

$\bo{L}^{\top}$ \texttt{= lqr}($\bo{A}^{\top}$, $\bo{C}^{\top}$, $\mathbf Q$, $\mathbf R$).

where $\mathbf Q$ and $\mathbf R$ are weight  matrices, determining the "sensitivity" or "aggressiveness" of the observer.


\end{flushleft}
\end{frame}




\begin{frame}{Observation and Control}
%\framesubtitle{LTI}
\begin{flushleft}

Thus we get dynamics+observer combination:

\begin{equation}
\begin{cases}
\dot {\bo{x}} = \bo{A} \bo{x} + \bo{B} \bo{u} \\
\hat{\dot {\bo{x}}} = \bo{A} \hat{\bo{x}} + \bo{B} \mathbf u + \bo{L}(\mathbf y - \bo{C} \hat{\bo{x}})\\
\bo{y} = \bo{C} \bo{x} \\
\bo{u} = -\bo{K} \hat{\bo{x}}
\end{cases}
\end{equation}

\bigskip

where $\bo{A} - \bo{B} \bo{K} \in \mathbb{H}$ and $\bo{A}^{\top} - 
\bo{C}^{\top} \bo{L}^{\top} \in \mathbb{H}$.


\end{flushleft}
\end{frame}




\begin{frame}{Observation and Control}
\framesubtitle{Stability analysis}
\begin{flushleft}

Let us re-write the dynamics

\begin{equation}
\begin{cases}
\dot {\bo{x}} = \textcolor{mydarkblue}{\bo{A}} \bo{x} \textcolor{mydarkpink}{- \bo{B} \bo{K}} \hat{\bo{x}} 
\\
\hat{\dot {\bo{x}}} = \textcolor{mydarkgray}{\bo{A}} \hat{\bo{x}} \textcolor{mydarkgray}{- \bo{B} \bo{K}} \hat{\bo{x}} + \textcolor{mydarkgreen}{\bo{L}\bo{C}} \bo{x} \textcolor{mydarkgray}{- \bo{L}\bo{C}} \hat{\bo{x}}
\end{cases}
\end{equation}

in a matrix form:

\begin{equation}
\begin{bmatrix}
\dot {\bo{x}} \\
\hat{\dot {\bo{x}}}
\end{bmatrix}
=
\begin{bmatrix}
\textcolor{mydarkblue}{\bo{A}} & \textcolor{mydarkpink}{-\bo{B}\bo{K}}\\
\textcolor{mydarkgreen}{\bo{L}\bo{C}} & (\textcolor{mydarkgray}{\bo{A} - \bo{B}\bo{K}-\bo{L}\bo{C}})
\end{bmatrix}
\begin{bmatrix}
\bo{x} \\
\hat{\bo{x}}
\end{bmatrix}
\end{equation}

\bigskip

We can't directly reason about eigenvalues of this matrix. Next slide will show a way to do it with a change of variables.

\end{flushleft}
\end{frame}




\begin{frame}{Observation and Control}
\framesubtitle{Change of variables}
\begin{flushleft}

Let us use the following substitution: $\bo{e} = \bo{x} - \hat{\bo{x}}$, which implies $\hat{\bo{x}} = \bo{x} - \bo{e}$:

Our system had form:

\begin{equation}
\begin{cases}
\dot {\bo{x}} = \textcolor{mydarkblue}{\bo{A} \bo{x} - \bo{B}\bo{K} \hat{\bo{x}}} \\
\hat{\dot {\bo{x}}} = \textcolor{mydarkpink}{\bo{A} \hat{\bo{x}} - \bo{B}\bo{K} \hat{\bo{x}} + \bo{L}\bo{C} \bo{x} - \bo{L}\bo{C} \hat{\bo{x}}}
\end{cases}
\end{equation}

Since $\dot{\bo{e}} = \textcolor{mydarkblue}{\dot{\bo{x}}} - \textcolor{mydarkpink}{\hat{\dot{\bo{x}}}}$, we get:
%
\[
\dot{\bo{e}} = 
\textcolor{mydarkblue}{\bo{A} \bo{x} - \bo{B}\bo{K} \hat{\bo{x}}} - 
\textcolor{mydarkpink}{(\bo{A} \hat{\bo{x}} - \bo{B}\bo{K} \hat{\bo{x}} + \bo{L}\bo{C} \bo{x} - \bo{L}\bo{C} \hat{\bo{x}})}
\]
%
\[
\dot{\bo{e}} = 
\bo{A} (\bo{x} - \hat{\bo{x}})  - \bo{L}\bo{C}(\bo{x} - \hat{\bo{x}})
\]
%
\[
\dot{\bo{e}} = 
(\bo{A}  - \bo{L}\bo{C})\bo{e}
\]

Equation $\dot {\bo{x}} = \bo{A} \bo{x} - \bo{B}\bo{K} \hat{\bo{x}}$ takes form:

\[
\dot {\bo{x}} = (\bo{A}-\bo{B}\bo{K}) \bo{x} +  \bo{B}\bo{K}\bo{e}
\]


\end{flushleft}
\end{frame}




\begin{frame}{Observation and Control}
\framesubtitle{Upper triangular form}
\begin{flushleft}

Collecting $\dot {\bo{x}}$ and $\dot{\bo{e}}$ we get:

\begin{equation}
\begin{cases}
\dot {\bo{x}} = (\bo{A}-\bo{B}\bo{K}) \bo{x} +  \bo{B}\bo{K}\bo{e} \\
\dot{\bo{e}} = 
(\bo{A}  - \bo{L}\bo{C})\bo{e}
\end{cases}
\end{equation}

In matrix form it becomes:

\begin{equation}
\begin{bmatrix}
\dot {\bo{x}} \\
\dot{\bo{e}}
\end{bmatrix}
=
\begin{bmatrix}
(\bo{A}-\bo{B}\bo{K}) & \bo{B}\bo{K} \\
0 & (\bo{A}  - \bo{L}\bo{C})
\end{bmatrix}
\begin{bmatrix}
\bo{x} \\
\bo{e}
\end{bmatrix}
\end{equation}

Eigenvalues of a upper block-triangular matrices equal to the union of the eigenvalues of the blocks on the main diagonal (see Appendix B). Hence here, the eigenvalues of the system are equal to the union of eigenvalues of $(\bo{A}-\bo{B}\bo{K})$ and $(\bo{A}  - \bo{L}\bo{C})$. 

\end{flushleft}
\end{frame}



\begin{frame}{Observation and Control}
\framesubtitle{Separation principle}
\begin{flushleft}
 
Since the eigenvalues of the system are equal to the union of eigenvalues of $(\bo{A}-\bo{B}\bo{K})$ and $(\bo{A}  - \bo{L}\bo{C})$, we can make the following observation:

\bigskip

\begin{alertblock}{Separation principle}
As long as the observer and the controller are stable independently, the overall system is stable too. This is called \emph{separation principle}.
\end{alertblock}

\end{flushleft}
\end{frame}




% \begin{frame}{Observation and Control}
% \framesubtitle{Affine case}
% \begin{flushleft}


% Affine case is almost the same:

% \begin{equation}
% \begin{cases}
% \dot {\bo{x}} = \bo{A} \bo{x} + \bo{B} \bo{u} + \bo{c}\\
% \hat{\dot {\bo{x}}} = \bo{A} \hat{\bo{x}} + \bo{B} \mathbf u + \bo{L}(\mathbf y - \bo{C} \hat{\bo{x}})  + \bo{c} \\
% \bo{y} = \bo{C} \bo{x} \\
% \bo{u} = -\bo{K} (\hat{\bo{x}} - \bo{x}^*(t)) + \bo{u}^*(t)
% \end{cases}
% \end{equation}

% \bigskip

% where $\bo{A} - \bo{B} \bo{K} < 0$ and $\bo{A}^{\top} - 
% \bo{c}^{\top} \bo{L}^{\top} < 0$.


% \end{flushleft}
% \end{frame}



\myqrframe



\begin{frame}{Appendix A. Eigenvalues of transpose}
%	\framesubtitle{General case: design via Riccati eq.}
	\begin{flushleft}
		
		Given matrix $\bo{M}$ and its eigenvalue $\lambda$ and eigenvector $\bo{v}$. we can prove that $\lambda$ is an eigenvector of $\bo{M}\T$:
		
		\begin{align}
			\bo{M}\bo{v} = \lambda \bo{v} \\
			\text{det}\ (\bo{M}- \bo{I} \lambda) = 0 \\
			\text{det}\ (\bo{M}\T- \bo{I} \lambda) = 0 \\
			\bo{M}\T\bo{u} = \lambda \bo{u}
		\end{align}
		
		We used the fact that determinant of a matrix is equal to the determinant of its transpose: $\text{det}\ (\bo{A}) = \text{det}\ (\bo{A}\T)$.
		
	\end{flushleft}
\end{frame}


\begin{frame}{Appendix B., 1}
		\framesubtitle{Eig. values of block-diagonal matrices}
	\begin{flushleft}
		
		Given matrix $\bo{M}$:
		%
		\begin{align}
			\bo{M} = 
			\begin{bmatrix}
				\bo{A} & \bo{B} \\ \bo{0} & \bo{C}
			\end{bmatrix}
		\end{align}
		
		Let $\lambda$, $\bo{v}$ be an eigenvalue and eigenvector of $\bo{A}$ and $\mu$, $\bo{u}$ be an eigenvalue and eigenvector of $\bo{C}$. We can prove that $\lambda$, $\bo{v}_M = \begin{bmatrix}
			\bo{v} \\ 0
		\end{bmatrix}$ are eigenvalue and eigenvector of $\bo{M}$:
	
		\begin{align}
			\begin{bmatrix}
				\bo{A} & \bo{B} \\ \bo{0} & \bo{C}
			\end{bmatrix}
		\begin{bmatrix}
			\bo{v} \\ \bo{0}
		\end{bmatrix}
	=
	\begin{bmatrix}
		\bo{A}\bo{v} \\ \bo{0}
	\end{bmatrix}
	=
	\lambda
	\begin{bmatrix}
		\bo{v} \\ \bo{0}
	\end{bmatrix}.
		\end{align}
		
	\end{flushleft}
\end{frame}



\begin{frame}{Appendix B., 2}
	\framesubtitle{Eig. values of block-diagonal matrices}
	\begin{flushleft}
		
		If $\mu$ is not an eigenvalue of $\bo{A}$, we can prove that $\mu$, $\bo{u}_M = \textcolor{mydarkpink}{\begin{bmatrix}
				(\bo{I}\mu - \bo{A})^{-1} \bo{B} \bo{u}  \\  \bo{u} 
		\end{bmatrix}}$ are eigenvalue and eigenvector of $\bo{M}$:
	
		\begin{align*}
	\begin{bmatrix}
		\bo{A} & \bo{B} \\ \bo{0} & \bo{C}
	\end{bmatrix}
\begin{bmatrix}
	(\bo{I}\mu - \bo{A})^{-1}\bo{B} \bo{u}  \\  \bo{u} 
\end{bmatrix}
	=
	\begin{bmatrix}
		\bo{A}(\bo{I}\mu - \bo{A})^{-1}\bo{B} \bo{u} + \bo{B} \bo{u}
		 \\ 
		 \bo{C}\bo{u}
	\end{bmatrix}
	= \\
	=
	\begin{bmatrix}
		(\bo{I}+\bo{A}(\bo{I}\mu - \bo{A})^{-1}) \bo{B} \bo{u}
		\\ 
		\mu \bo{u}
	\end{bmatrix} 
=
	\begin{bmatrix}
	(\bo{I}\mu - \bo{A}+\bo{A})(\bo{I}\mu - \bo{A})^{-1} \bo{B} \bo{u}
	\\ 
	\mu \bo{u}
	\end{bmatrix} 
= \\
=
	\begin{bmatrix}
	\mu(\bo{I}\mu - \bo{A})^{-1} \bo{B} \bo{u}
	\\ 
	\mu \bo{u}
	\end{bmatrix} 
=
\mu 
\textcolor{mydarkpink}{
\begin{bmatrix}
(\bo{I}\mu - \bo{A})^{-1} \bo{B} \bo{u}
\\ 
\bo{u}
\end{bmatrix} 
}.
	\end{align*}	
	
	
	
	Counting the number of eigenvalues we observe that eigenvalues of $\bo{M}$ include only eigenvalues of $\bo{A}$ and $\bo{B}$.
		
	\end{flushleft}
\end{frame}


\end{document}
